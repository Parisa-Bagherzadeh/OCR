{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQzPsAJjt65x"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaCewM-Xufwx"
      },
      "outputs": [],
      "source": [
        "%cd deep-text-recognition-benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-gn1yXi0QXC"
      },
      "outputs": [],
      "source": [
        "!gdown 1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KWdz1EJ1HGd"
      },
      "outputs": [],
      "source": [
        "!pip install lmdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De1RGZe8BHXM"
      },
      "outputs": [],
      "source": [
        "!pip install fire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpFJqBsuQLlv"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/plate_img-test.zip -d /content/drive/MyDrive/mydataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ3iamzhJuSp"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/plate_img-validation.zip -d /content/drive/MyDrive/plate_img-validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD-mWwHVXIRW",
        "outputId": "bf0e923f-a99a-46c3-ac8a-41d35250fe59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files copied successfully.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "source_folder = '/content/drive/MyDrive/data/data/train'\n",
        "destination_folder = '/content/drive/MyDrive/mydataset/train'\n",
        "\n",
        "\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "files_to_copy = os.listdir(source_folder)\n",
        "\n",
        "for file_name in files_to_copy:\n",
        "    source_file_path = os.path.join(source_folder, file_name)\n",
        "    destination_file_path = os.path.join(destination_folder, file_name)\n",
        "    shutil.copy(source_file_path, destination_file_path)\n",
        "\n",
        "print(\"Files copied successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmaVMbh8ZWhC",
        "outputId": "3f45eb34-478e-4f28-e504-63f76ccefc4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction completed. Names written to: /content/drive/MyDrive/dataset/gt_validation.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from lxml import etree\n",
        "\n",
        "\n",
        "dict = {\n",
        "        'الف':'A',\n",
        "        'ب':'B',\n",
        "        'پ':'P',\n",
        "        'ت':'T',\n",
        "        'ث':'Y',\n",
        "        'ز':'Z',\n",
        "        'ش': 'X',\n",
        "        'ع': 'E',\n",
        "        'ف': 'F',\n",
        "        'ک': 'K',\n",
        "        'گ': 'G',\n",
        "        'D': 'D',\n",
        "        'S': 'S',\n",
        "        'ج': 'J',\n",
        "        'د': 'W',\n",
        "        'س': 'C',\n",
        "        'ص': 'U',\n",
        "        'ط': 'R',\n",
        "        'ق': 'Q',\n",
        "        'ل': 'L',\n",
        "        'م': 'M',\n",
        "        'ن': 'N',\n",
        "        'و': 'V',\n",
        "        'ه': 'H',\n",
        "        'ی': 'I',\n",
        "        '0': '0',\n",
        "        '1': '1',\n",
        "        '2': '2',\n",
        "        '3': '3',\n",
        "        '4': '4',\n",
        "        '5': '5',\n",
        "        '6': '6',\n",
        "        '7': '7',\n",
        "        '8': '8',\n",
        "        '9': '9',\n",
        "}\n",
        "xml_dir = '/content/drive/MyDrive/dataset_/train'\n",
        "\n",
        "output_txt_file = '/content/drive/MyDrive/dataset/gt_validation.txt'\n",
        "\n",
        "os.makedirs(os.path.dirname(output_txt_file), exist_ok=True)\n",
        "\n",
        "\n",
        "def extract_and_write_names(xml_file, txt_file):\n",
        "    parser = etree.XMLParser(encoding=\"utf-8\")\n",
        "    tree = etree.parse(xml_file, parser=parser)\n",
        "    root = tree.getroot()\n",
        "\n",
        "\n",
        "    xml_file_name = os.path.splitext(os.path.basename(xml_file))[0]\n",
        "\n",
        "    with open(txt_file, 'a', encoding='utf-8') as txt_file:\n",
        "        txt_file.write(f\"validation/{xml_file_name}.jpg\")\n",
        "        txt_file.write(\"\\t\")\n",
        "        for name_element in root.iter('name'):\n",
        "            name = name_element.text.strip() if name_element.text else \"\"\n",
        "            if name in dict:\n",
        "                txt_file.write(f\"{dict[name]}\")\n",
        "            else:\n",
        "                txt_file.write(\"@\")\n",
        "        txt_file.write(\"\\n\")\n",
        "\n",
        "for xml_file_name in os.listdir(xml_dir):\n",
        "    if xml_file_name.endswith('.xml'):\n",
        "\n",
        "        xml_file_path = os.path.join(xml_dir, xml_file_name)\n",
        "\n",
        "        extract_and_write_names(xml_file_path, output_txt_file)\n",
        "\n",
        "print(\"Extraction completed. Names written to:\", output_txt_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAVdlG1bIsJq"
      },
      "outputs": [],
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath /content/drive/MyDrive/mydataset --gtFile /content/drive/MyDrive/mydataset/gt_train.txt --outputPath /content/drive/MyDrive/dataset/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Fvyr-cmv9Pc"
      },
      "outputs": [],
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath /content/drive/MyDrive/mydataset --gtFile /content/drive/MyDrive/mydataset/gt_validation.txt --outputPath /content/drive/MyDrive/dataset/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_LVRICm0Ouf",
        "outputId": "1d29f37d-eb35-4b9b-91bf-8af07dfc620e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: /content/drive/MyDrive/dataset/train\n",
            "opt.select_data: ['/']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    /content/drive/MyDrive/dataset/train\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 18211\n",
            "num total samples of /: 18211 x 1.0 (total_data_usage_ratio) = 18211\n",
            "num samples of / per batch: 192 x 1.0 (batch_ratio) = 192\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 192 = 192\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    /content/drive/MyDrive/dataset/validation\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 2627\n",
            "--------------------------------------------------------------------------------\n",
            "model input parameters 32 100 20 1 512 256 38 8 TPS ResNet BiLSTM Attn\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (Transformation): TPS_SpatialTransformerNetwork(\n",
            "      (LocalizationNetwork): LocalizationNetwork(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): ReLU(inplace=True)\n",
            "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (10): ReLU(inplace=True)\n",
            "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (14): ReLU(inplace=True)\n",
            "          (15): AdaptiveAvgPool2d(output_size=1)\n",
            "        )\n",
            "        (localization_fc1): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "        )\n",
            "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
            "      )\n",
            "      (GridGenerator): GridGenerator()\n",
            "    )\n",
            "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
            "      (ConvNet): ResNet(\n",
            "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer2): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "        (layer3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (layer4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
            "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
            "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Attention(\n",
            "      (attention_cell): AttentionCell(\n",
            "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
            "        (rnn): LSTMCell(294, 256)\n",
            "      )\n",
            "      (generator): Linear(in_features=256, out_features=38, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Trainable params num :  49555182\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "exp_name: TPS-ResNet-BiLSTM-Attn-Seed1111\n",
            "train_data: /content/drive/MyDrive/dataset/train\n",
            "valid_data: /content/drive/MyDrive/dataset/validation\n",
            "manualSeed: 1111\n",
            "workers: 4\n",
            "batch_size: 192\n",
            "num_iter: 3000\n",
            "valInterval: 500\n",
            "saved_model: \n",
            "FT: False\n",
            "adam: False\n",
            "lr: 1\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "baiduCTC: False\n",
            "select_data: ['/']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 8\n",
            "imgH: 32\n",
            "imgW: 100\n",
            "rgb: False\n",
            "character: 0123456789abcdefghijklmnopqrstuvwxyz\n",
            "sensitive: False\n",
            "PAD: False\n",
            "data_filtering_off: False\n",
            "Transformation: TPS\n",
            "FeatureExtraction: ResNet\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: Attn\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 512\n",
            "hidden_size: 256\n",
            "num_gpu: 1\n",
            "num_class: 38\n",
            "---------------------------------------\n",
            "\n",
            "[1/3000] Train loss: 3.65339, Valid loss: 3.51919, Elapsed_time: 18.34954\n",
            "Current_accuracy : 0.000, Current_norm_ED  : 0.06\n",
            "Best_accuracy    : 0.000, Best_norm_ED     : 0.06\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "42l41619                  | kkkkk                     | 0.0000\tFalse\n",
            "72u58388                  | 233                       | 0.0001\tFalse\n",
            "25u41399                  | k3322222                  | 0.0000\tFalse\n",
            "47m67799                  | w333                      | 0.0000\tFalse\n",
            "51w66888                  | k333                      | 0.0000\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[500/3000] Train loss: 2.09337, Valid loss: 1.36425, Elapsed_time: 606.41129\n",
            "Current_accuracy : 0.152, Current_norm_ED  : 0.51\n",
            "Best_accuracy    : 0.152, Best_norm_ED     : 0.51\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "81q16777                  | 81j16677                  | 0.0008\tFalse\n",
            "75j22211                  | 55j77211                  | 0.0006\tFalse\n",
            "19q68                     | 19m64668                  | 0.0004\tFalse\n",
            "82u33816                  | 82u62116                  | 0.0007\tFalse\n",
            "89q31766                  | 89m22166                  | 0.0008\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[1000/3000] Train loss: 0.51823, Valid loss: 0.32191, Elapsed_time: 1184.41641\n",
            "Current_accuracy : 78.911, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 78.911, Best_norm_ED     : 0.93\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "91u62434                  | 91u62434                  | 0.8131\tTrue\n",
            "11l7839                   | 11l78399                  | 0.1887\tFalse\n",
            "9i69713                   | 69i69713                  | 0.0533\tFalse\n",
            "71i67733                  | 71i67733                  | 0.8370\tTrue\n",
            "82t4543                   | 82t454                    | 0.2497\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[1500/3000] Train loss: 0.21453, Valid loss: 0.33350, Elapsed_time: 1762.22843\n",
            "Current_accuracy : 76.285, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 78.911, Best_norm_ED     : 0.93\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "13q36466                  | 13q36466                  | 0.8501\tTrue\n",
            "52m28955                  | 52m28955                  | 0.8728\tTrue\n",
            "13w86744                  | 13w86744                  | 0.9284\tTrue\n",
            "41m96710                  | 41m7710                   | 0.0311\tFalse\n",
            "86w49477                  | 86w49477                  | 0.9259\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[2000/3000] Train loss: 0.12629, Valid loss: 0.37226, Elapsed_time: 2341.90812\n",
            "Current_accuracy : 78.949, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 78.949, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "v9110                     | 76v69110                  | 0.2592\tFalse\n",
            "39w467                    | 2w46744                   | 0.1507\tFalse\n",
            "87e44668                  | 87e44668                  | 0.9403\tTrue\n",
            "75j22211                  | 75j22211                  | 0.4668\tTrue\n",
            "4c9254                    | 4u2253                    | 0.1238\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[2500/3000] Train loss: 0.08032, Valid loss: 0.37995, Elapsed_time: 2920.68782\n",
            "Current_accuracy : 79.596, Current_norm_ED  : 0.94\n",
            "Best_accuracy    : 79.596, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "22t61212                  | 22t61212                  | 0.9789\tTrue\n",
            "56u41414                  | 56u41414                  | 0.9880\tTrue\n",
            "84r48318                  | 84r48318                  | 0.9662\tTrue\n",
            "18e38498                  | 18e38498                  | 0.9609\tTrue\n",
            "4q92877                   | 64q92877                  | 0.9677\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[3000/3000] Train loss: 0.04611, Valid loss: 0.44820, Elapsed_time: 3498.92189\n",
            "Current_accuracy : 76.551, Current_norm_ED  : 0.93\n",
            "Best_accuracy    : 79.596, Best_norm_ED     : 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "29q74241                  | 99q74241                  | 0.8523\tFalse\n",
            "15j1                      | 55j416                    | 0.2188\tFalse\n",
            "64u37234                  | 64u37234                  | 0.9926\tTrue\n",
            "38j83967                  | 38j83967                  | 0.9955\tTrue\n",
            "79q44516                  | 79q64516                  | 0.7479\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "end the training\n"
          ]
        }
      ],
      "source": [
        "!python3 train.py \\\n",
        "--train_data /content/drive/MyDrive/dataset/train --valid_data /content/drive/MyDrive/dataset/validation \\\n",
        "--select_data / --batch_ratio 1 --batch_max_length 8 --valInterval 500 --num_iter 3000\\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH5FbSNYHKyW"
      },
      "outputs": [],
      "source": [
        "!python3 test.py \\\n",
        "--eval_data data_lmdb_release/evaluation --benchmark_all_eval \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--saved_model /content/deep-text-recognition-benchmark/saved_models/TPS-ResNet-BiLSTM-Attn-Seed1111/best_accuracy.pth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
